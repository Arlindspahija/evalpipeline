Das Projekt vereinfacht die Bewertung von Large Language Models (LLMs) auf Azure AI Foundry. Das Tool bietet umfassende Analysen mit Kennzahlen wie Relevanz, Kohärenz und F1-Score und ermöglicht die Integration mit Azure-Diensten.

Hauptfunktionen:
	•	Anpassbare Evaluierung: Tests mit verschiedenen Datensätzen und Bewertungsmetriken.
	•	Azure-Integration: Nahtlose Nutzung von Azure OpenAI-Modellen.
	•	Ergebnisverfolgung: Speicherung und Vergleich von Evaluierungen.

Nutzung:
	1.	Repository klonen und Abhängigkeiten installieren
	2.	Umgebungsvariablen einrichten
	3.	Evaluierung mit evaluation_pipeline.py starten.

Das Projekt unterstützt Anpassungen und lädt zur Mitwirkung ein.